{
  "hash": "56cf88f997d1f6c063b031eb6aa66e2d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Sampling Distribution and Central Limit Theorem `<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 640 512\" style=\"height:1em;width:1.25em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M0 241.1C0 161 65 96 145.1 96c38.5 0 75.4 15.3 102.6 42.5L320 210.7l72.2-72.2C419.5 111.3 456.4 96 494.9 96C575 96 640 161 640 241.1v29.7C640 351 575 416 494.9 416c-38.5 0-75.4-15.3-102.6-42.5L320 301.3l-72.2 72.2C220.5 400.7 183.6 416 145.1 416C65 416 0 351 0 270.9V241.1zM274.7 256l-72.2-72.2c-15.2-15.2-35.9-23.8-57.4-23.8C100.3 160 64 196.3 64 241.1v29.7c0 44.8 36.3 81.1 81.1 81.1c21.5 0 42.2-8.5 57.4-23.8L274.7 256zm90.5 0l72.2 72.2c15.2 15.2 35.9 23.8 57.4 23.8c44.8 0 81.1-36.3 81.1-81.1V241.1c0-44.8-36.3-81.1-81.1-81.1c-21.5 0-42.2 8.5-57.4 23.8L365.3 256z\"/></svg>`{=html}'\ntitle-slide-attributes:\n  data-background-image: ../images/bg.png\n  # data-background-size: stretch\n  # data-slide-number: none\nformat: \n  live-revealjs: \n    output-file: 08-sampling-dist-clt-slides.html\n    # theme: slides.scss\nwebr:\n  cell-options:\n    autorun: false\n  packages:\n    - tidyverse\nknitr:\n  opts_chunk:\n    out-width: 100%\n    echo: false\n---\n\n\n# {visibility=\"hidden\"}\n\n\\def\\bx{\\mathbf{x}}\n\\def\\bg{\\mathbf{g}}\n\\def\\bw{\\mathbf{w}}\n\\def\\bbeta{\\boldsymbol \\beta}\n\\def\\bX{\\mathbf{X}}\n\\def\\by{\\mathbf{y}}\n\\def\\bH{\\mathbf{H}}\n\\def\\bI{\\mathbf{I}}\n\\def\\bS{\\mathbf{S}}\n\\def\\bW{\\mathbf{W}}\n\\def\\T{\\text{T}}\n\\def\\cov{\\mathrm{Cov}}\n\\def\\cor{\\mathrm{Corr}}\n\\def\\var{\\mathrm{Var}}\n\\def\\E{\\mathrm{E}}\n\\def\\bmu{\\boldsymbol \\mu}\n\\DeclareMathOperator*{\\argmin}{arg\\,min}\n\\def\\Trace{\\text{Trace}}\n\n\n\n\n<!-- begin: webr fodder -->\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n<!-- end: webr fodder -->\n\n# [Sampling Distribution]{.orange}{background-image=\"./images/08-sampling-dist-clt/Bernoulli.jpg\" background-size=\"cover\" background-position=\"50% 50%\" background-color=\"#447099\"}\n\n::: notes\n- Sampling distribution is an important concept that connect probability and statistics together. \n- Til now, we can start talk a little bit about statistical inference. \n- After we finish the discussion of probability this week, we are going to formally study statistical inference next week.\n- To do statistical inference, we use the sampling distribution a lot, and that's why we have to learn what it is before doing statistical inference.\n:::\n\n## Parameter\n\n- **Parameters** in a probability distribution are the values describing the entire distribution.\n  + <span style=\"color:blue\"> Binomial: two parameters $n$ and $\\pi$ </span>\n  + <span style=\"color:blue\"> Poisson: one parameter $\\lambda$ </span>\n  + <span style=\"color:blue\"> Normal: two parameters $\\mu$ and $\\sigma$ </span>\n  \n. . .\n\n- In statistics, we usually assume our target population follows some distribution, but _its parameters are **unknown** to us_.\n\n. . .\n\n::::: columns\n\n::: {.column width=\"50%\"}\n\n<span style=\"color:blue\"> Human weight follows $N(\\mu, \\sigma^2)$ </span>\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-sampling-dist-clt/weight.jpeg){fig-align='center' width=60%}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n<span style=\"color:blue\"> # of snowstorms in one year follows $Poisson(\\lambda)$ </span>\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-sampling-dist-clt/storm.jpeg){fig-align='center' width=55%}\n:::\n:::\n\n:::\n\n:::::\n\n## Treat Each Data Point as a Random Variable\n\n- $n$ random variables $X_1, X_2, \\dots, X_n$.\n\n- $X_1, X_2, \\dots, X_n$ come from the **same** distribution.\n\n::: alert\nView $X_i$ as *a data point to be drawn* from a population with some distribution, say $N(\\mu, \\sigma^2)$.\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](08-sampling-dist-clt_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n::: notes\n- Previously when we talk about probability distributions, we usually assume there is a r.v. that follows some distribution, right? For example, $X$ from binomial, poisson, normal\n- Now, let's assume we have a bunch of r.v.\n- $n$ random variables: $X_1, X_2, \\dots, X_n$.\n- Assume $X_1, X_2, \\dots, X_n$ follow the **same** distribution, e.g., <span style=\"color:blue\"> $X_i \\sim N(\\mu, \\sigma^2), i = 1, \\dots, n$ </span>.\n:::\n\n\n## Treat Each Data Point as a Random Variable\n\n- Assume that $X_1, X_2, \\dots, X_n$ are **independent**, i.e., the distribution/value of $X_i$ is not affected by any other $X_j$.\n\n- With the same distribution, $X_1, X_2, \\dots, X_n$ are _**i**ndependent and **i**dentically **d**istributed_ (i.i.d.): <span style=\"color:blue\"> $X_1, X_2, \\dots, X_n \\stackrel{iid}{\\sim} N(\\mu, \\sigma^2)$ </span>\n\n- $(X_1, X_2, \\dots, X_n)$ is a **random sample** of size $n$ from the population. \n  + <span style=\"color:blue\"> $X_1, X_2, \\dots, X_{50}$ are randomly selected SAT scores from the SAT score population that follows $N(1100, 200^2)$ </span>\n\n. . .\n\n::: alert\n- *Before* we actually collect the data, the data $X_1, X_2, \\dots, X_n$ are random variables from the population distribution $N(\\mu, \\sigma^2)$.\n- Once we collect the data, we know the *realized* value of these random variables, $x_1, x_2, \\dots, x_n$.\n:::\n  \n  \n::: notes\n- Assume $X_1, X_2, \\dots, X_n$ follow the **same** distribution.\n- Assume that $X_1, X_2, \\dots, X_n$ are **independent**, i.e., the distribution of $X_i$ is not affected by any other $X_j$.\n- Now this is where we connect the idea of sample data and population with the random variable and the distribution.\n- View $X_i$ as a data point to be drawn from a population with some distribution, say $N(\\mu, \\sigma^2)$.\n- We haven't really sample those points yet. Before we actually collect the data, they are random variables, and we don't know their value.\n- Once we collect the data, we know the realized value of these random variables.\n- $(X_1, X_2, \\dots, X_n)$ is our random sample data that are sampled or drawn from the population that are assumed normally distributed with mean mu and SD sigma.\n\nWhen we say $X$ follows some distribution, it means that\n:::\n\n\n## Sampling Distribution\n\n- Any value computed from a sample $(X_1, X_2, \\dots, X_n)$ is called a **(sample) statistic**.\n  + <span style=\"color:blue\"> Sample mean $\\frac{1}{n}\\sum_{i=1}^n X_i$ is a statistic. </span>\n\n::: question\nCan you provide another statistic?\n:::\n\n. . .\n\n::: alert\n<span style=\"color:blue\"> Sample variance $\\frac{\\sum_{i=1}^n \\left(X_i - \\overline{X}\\right)^2}{n-1}$ is a statistic. </span>\n:::\n\n. . .\n\n- Since $X_1, X_2, \\dots, X_n$ are random variables, *any transformation or function of $(X_1, X_2, \\dots, X_n)$, or statistic, is also a random variable.* \n\n\n- The probability distribution of a statistic is called the **sampling distribution** of that statistic.\n\n. . .\n\n::: question\nDoes the sample mean $\\overline{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$ have a sampling distribution?\n:::\n\n\n\n## Sampling Distribution\n\n- It is the probability distribution of that statistic if we *__were to repeatedly__ draw samples of the same size from the population*.\n\n::: tiny\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Biostatistics for the Biological and Health Sciences p.241](images/08-sampling-dist-clt/sampling_dist_mean.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n## Sampling Distribution\n\n- [Sampling Distribution Applet](https://www.statcrunch.com/applets/type3&samplingdist)\n\n::: question\nWhat are the differences between the sampling distribution of $\\overline{X}$ and the population distribution each individual r.v. $X_i$ is drawn from?\n:::\n\n. . .\n\n- Sample means $(\\overline{X})$ are <span style=\"color:red\"> **less variable** </span> than individual observations $X_i$.\n\n- Sample means $(\\overline{X})$ are <span style=\"color:red\"> **more normal** </span> than individual observations $X_i$. \n\n\n\n::: notes\n- [Sampling Distribution Applet](http://www.mscs.mu.edu/~mehdi/applets/sample_dist/index.html)\n:::\n\n## Example: Sampling Distribution of the Sample Mean\n\n- Roll a fair die 3 times ðŸŽ²ðŸŽ² ðŸŽ² independently to obtain 3 values from the population $\\{1, 2, 3, 4, 5, 6\\}$.\n\n- Repeat the process 10,000 times and plot the histogram of the sampling mean.\n\n::::: columns\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](08-sampling-dist-clt_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](08-sampling-dist-clt_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n:::::\n\n\n##\n\n<iframe src=\"https://cheyu.shinyapps.io/rolling-die/\"\n        width=\"100%\" height=\"90%\" style=\"border:none;\">\n</iframe>\n\n\n## Sampling Distribution of Sample Mean\n\n<!-- - Assume that the population distribution has mean $\\mu$ and standard deviation $\\sigma$. -->\n- Suppose $(X_1, \\dots, X_n)$ is the random sample from a population distribution with mean $\\mu$ and standard deviation $\\sigma$.\n\n- The mean of the sampling distribution of the sample mean, $\\overline{X} = \\frac{\\sum_{i=1}^nX_i}{n}$, is <span style=\"color:blue\"> $\\mu_{\\overline{X}} = \\mu$ </span>.\n\n- The standard deviation of the sampling distribution of the sample mean $\\overline{X}$ is <span style=\"color:blue\"> $\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}$ </span>.\n<!-- - $\\sigma_{\\overline{X}}$ is also known as the **standard error** of $\\overline{X}$. -->\n\n- If the population distribution is <span style=\"color:blue\"> $N(\\mu, \\sigma^2)$ </span>, the sampling distribution of $\\overline{X}$ is **exactly** <span style=\"color:blue\"> $N\\left(\\mu, \\frac{\\sigma^2}{n} \\right)$ </span>.\n\n::: notes\n$\\sigma$.\n- Suppose $(X_1, \\dots, X_n)$ is the random sample from ach $X_i$ is sampled from the same population (same $\\mu$ and same $\\sigma$).\n:::\n\n\n\n## Sampling Distribution of Sample Mean Illustration\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](08-sampling-dist-clt_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Standardization of Sample Mean \n\n- For a single random variable $X \\sim N(\\mu, \\sigma^2)$, $Z = \\frac{X - \\mu}{\\sigma} \\sim N(0, 1)$.\n\n- For the sample mean of $n$ variables, $\\overline{X} \\sim N(\\mu_{\\overline{X}}, \\sigma^2_{\\overline{X}}) = N(\\mu, \\frac{\\sigma^2}{n})$, and hence \n\n<span style=\"color:blue\">$$Z = \\frac{\\overline{X} - \\mu_{\\overline{X}}}{\\sigma_{\\overline{X}}} = \\frac{\\overline{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim N(0, 1)$$</span>\n  <!-- + The solution is the **Central Limit Theorem**! -->\n  \n  \n## Example - Psychomotor retardation\n\n::::: columns\n\n::: {.column width=\"90%\"}\n\n- Psychomotor retardation scores for a group of patients have a normal distribution with a mean of 930 and a standard deviation of 130.\n\n- What is the probability that the *mean* retardation score of a random sample of 20 patients was between 900 and 960?\n\n:::\n\n::: {.column width=\"10%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-sampling-dist-clt/depression.jpeg){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n:::::\n\n. . .\n\n- $X_1, \\dots, X_{20}  \\stackrel{iid}{\\sim} N(930, 130^2)$, then $\\overline{X} = \\frac{\\sum_{i=1}^{20}X_i}{20} \\sim N\\left(930, \\frac{130^2}{20} \\right)$.\n\n. . .\n\n$$\\small \\begin{align} \nP(900 < \\overline{X} < 960) &= P\\left( \\frac{900-930}{130/\\sqrt{20}} < \\frac{\\overline{X}-930}{130/\\sqrt{20}} < \\frac{960-930}{130/\\sqrt{20}}\\right)=P(-1.03 < Z < 1.03)\\\\\n&=P(Z < 1.03) - P(Z < -1.03)\n  \\end{align}$$\n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npnorm(1.03) - pnorm(-1.03)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.697\n```\n\n\n:::\n:::\n\n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npnorm(960, mean = 930, sd = 130/sqrt(20)) - pnorm(900, mean = 930, sd = 130/sqrt(20))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.698\n```\n\n\n:::\n:::\n\n\n\n# [Central Limit Theorem]{.orange}{background-image=\"./images/08-sampling-dist-clt/magic.jpg\" background-size=\"cover\" background-position=\"50% 50%\" background-color=\"#447099\"}\n\n## Central Limit Theorem\n\n- If $X_i \\stackrel{iid}{\\sim} N(\\mu, \\sigma^2)$ , then $\\overline{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n} \\right)$.\n\n- <span style=\"color:blue\"> What if the population distribution is **NOT** normal? </span> \n\n. . .\n\n<br>\n\n<br>\n\n<br>\n\n::: center\n::: large\nThe **central limit theorem (CLT)** gives us the answer!\n:::\n:::\n\n\n## Why Use Normal? <span style=\"color: red\">**Central Limit Theorem**</span>\n**Central Limit Theorem (CLT)**: \n\n> Suppose $\\overline{X}$ is from a random sample of size $n$ and from a population distribution having mean $\\mu$ and standard deviation $\\sigma < \\infty$. <br>\nAs $n$ increases, the sampling distribution of $\\overline{X}$ looks **more and more like $N(\\mu, \\sigma^2/n)$, regardless of the distribution from which we are sampling!**\n\n::: tiny\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![https://en.wikipedia.org/wiki/Central_limit_theorem#/media/File:IllustrationCentralTheorem.png](./images/08-sampling-dist-clt/clt.png){fig-align='center' width=67%}\n:::\n:::\n\n:::\n\n\n## CLT Illustration: A Right-Skewed Distribution\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](08-sampling-dist-clt_files/figure-revealjs/unnamed-chunk-13-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## CLT Illustration: A U-shaped Distribution\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](08-sampling-dist-clt_files/figure-revealjs/unnamed-chunk-14-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n<!-- ## Central Limit Theorem Applet -->\n\n<!-- {{< include prob-clt-ojs.qmd >}} -->\n\n\n\n## Why CLT is Important?\n\n<!-- - Many statistics have distributions that are approximately normal for large sample sizes, even when we are sampling from a distribution that is not normal. -->\n- Many well-developed statistical methods are based on normal distribution assumption.\n\n- With CLT, we can use those methods even if we are sampling from a non-normal distribution, or we have no idea of the population distribution, provided that the sample size is large.\n\n\n## CLT Example\n\n\n::::: columns\n\n::: {.column width=\"85%\"}\n\n- Suppose that selling prices of houses in Milwaukee are known to have a mean of $382,000 and a standard deviation of $150,000.\n\n- In 100 randomly selected sales, what is the probability the *average* selling price is more than $400,000?\n\n:::\n\n::: {.column width=\"15%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-sampling-dist-clt/house.jpeg){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n:::::\n\n. . .\n\n<!-- - We need the sampling distribution of the average selling price in order to obtain the probability.  -->\n- Since the sample size is fairly large $(n = 100)$, by CLT, the sampling distribution of the average selling price is approximately normal with mean 382,000 and SD $150,000 / \\sqrt{100}$.\n\n- $P(\\overline{X} > 400000) = P\\left(\\frac{\\overline{X} - 382000}{150000/\\sqrt{100}}  > \\frac{400000 - 382000}{150000/\\sqrt{100}}\\right) \\approx P(Z > 1.2)$ where $Z \\sim N(0, 1)$.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npnorm(1.2, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.115\n```\n\n\n:::\n\n```{.r .cell-code}\npnorm(400000, mean = 382000, sd = 150000/sqrt(100), lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.115\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n",
    "supporting": [
      "08-sampling-dist-clt_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}