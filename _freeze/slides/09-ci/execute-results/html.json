{
  "hash": "c7027c94a08550485e3b89898a9c0ec4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Statistical Inference: Point and Interval Estimation `<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M192 104.8c0-9.2-5.8-17.3-13.2-22.8C167.2 73.3 160 61.3 160 48c0-26.5 28.7-48 64-48s64 21.5 64 48c0 13.3-7.2 25.3-18.8 34c-7.4 5.5-13.2 13.6-13.2 22.8c0 12.8 10.4 23.2 23.2 23.2H336c26.5 0 48 21.5 48 48v56.8c0 12.8 10.4 23.2 23.2 23.2c9.2 0 17.3-5.8 22.8-13.2c8.7-11.6 20.7-18.8 34-18.8c26.5 0 48 28.7 48 64s-21.5 64-48 64c-13.3 0-25.3-7.2-34-18.8c-5.5-7.4-13.6-13.2-22.8-13.2c-12.8 0-23.2 10.4-23.2 23.2V464c0 26.5-21.5 48-48 48H279.2c-12.8 0-23.2-10.4-23.2-23.2c0-9.2 5.8-17.3 13.2-22.8c11.6-8.7 18.8-20.7 18.8-34c0-26.5-28.7-48-64-48s-64 21.5-64 48c0 13.3 7.2 25.3 18.8 34c7.4 5.5 13.2 13.6 13.2 22.8c0 12.8-10.4 23.2-23.2 23.2H48c-26.5 0-48-21.5-48-48V343.2C0 330.4 10.4 320 23.2 320c9.2 0 17.3 5.8 22.8 13.2C54.7 344.8 66.7 352 80 352c26.5 0 48-28.7 48-64s-21.5-64-48-64c-13.3 0-25.3 7.2-34 18.8C40.5 250.2 32.4 256 23.2 256C10.4 256 0 245.6 0 232.8V176c0-26.5 21.5-48 48-48H168.8c12.8 0 23.2-10.4 23.2-23.2z\"/></svg>`{=html}'\ntitle-slide-attributes:\n  data-background-image: ../images/bg.png\n  # data-background-size: stretch\n  # data-slide-number: none\nformat: \n  live-revealjs: \n    output-file: 09-ci-slides.html\n    # theme: slides.scss\nwebr:\n  cell-options:\n    autorun: false\n  packages:\n    - tidyverse\nknitr:\n  opts_chunk:\n    out-width: 100%\n    echo: false\n---\n\n\n# {visibility=\"hidden\"}\n\n\\def\\bx{\\mathbf{x}}\n\\def\\bg{\\mathbf{g}}\n\\def\\bw{\\mathbf{w}}\n\\def\\bbeta{\\boldsymbol \\beta}\n\\def\\bX{\\mathbf{X}}\n\\def\\by{\\mathbf{y}}\n\\def\\bH{\\mathbf{H}}\n\\def\\bI{\\mathbf{I}}\n\\def\\bS{\\mathbf{S}}\n\\def\\bW{\\mathbf{W}}\n\\def\\T{\\text{T}}\n\\def\\cov{\\mathrm{Cov}}\n\\def\\cor{\\mathrm{Corr}}\n\\def\\var{\\mathrm{Var}}\n\\def\\E{\\mathrm{E}}\n\\def\\bmu{\\boldsymbol \\mu}\n\\DeclareMathOperator*{\\argmin}{arg\\,min}\n\\def\\Trace{\\text{Trace}}\n\n\n\n\n<!-- begin: webr fodder -->\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n<!-- end: webr fodder -->\n\n# Foundations for Inference\n\n- ### Estimation: Point and Interval Estimation\n- ### Testing\n\n\n## Inference Framework\n\n- **Inferential statistics uses sample data to learn about an unknown population**.\n\n- Idea: Assume the target population follows some distribution but with **unknown** parameters.\n  + <span style=\"color:blue\"> Assume the population is normally distributed, but don't know its mean and/or variance. Marquette students' mean GPA for example. </span>\n  \n- Goal: **Learning the unknown parameters** of the assumed population distribution.\n\n\n- Two approaches in parameter learning: **Estimation** and **Hypothesis testing**.\n\n::::: columns\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-ci_files/figure-revealjs/unnamed-chunk-2-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-ci_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n:::::\n\n\n\n::: notes\n\n- We finally are going to study inferential statistics that **uses sample data to learn about an unknown population**. (Getting harder! Be careful!)\n- We are interested in **learning unknown parameters** of the assumed population distribution, since knowledge of the parameters yield knowledge of the entire population.\n- In parameter learning, we consider two approaches, **estimation** and **hypothesis testing**.\n  + <span style=\"color:blue\"> Learn the mean and/or variance of the normal distribution. </span>\n  \n:::\n\n\n## Point Estimator\n<!-- - We discuss estimation this week and testing next week.  -->\n<!-- - It's natural to seek a \"good\" estimator of a parameter. -->\n\n::: question\nIf you can **use only one single number** to guess the unknown population mean $\\mu$, what would you like to use?\n:::\n\n. . .\n\n::: alert\nThe one single point used to estimate the unknown parameter is called a **point estimator**.\n:::\n\n. . .\n\n- A **point estimator** is any function of data $(X_1, X_2, \\dots, X_n)$ *(Before actually being collected).*\n  + **Any statistic is a point estimator**.\n  \n- A **point estimate** is a value of a point estimator used to estimate a population parameter. *(A value calculated using the collected data).*\n\n- Sample mean $(\\overline{X})$ is a statistic and a point estimator for the population mean $\\mu$.\n\n\n::: notes\n\n<!-- - We discuss estimation this week and testing next week.  -->\n<!-- - It's natural to seek a \"good\" estimator of a parameter. -->\n- A **point estimator** is any function of a sample $(X_1, X_2, \\dots, X_n)$.\n  + **Any statistic is a point estimator**.\n- A **point estimate** is a value of a point estimator used to estimate a population parameter.\n- Sample mean $(\\overline{X})$ is a statistic and a point estimator for the population mean $\\mu$.\n\n:::\n\n\n## Sample Mean as an Point Estimator\n\n- Draw 5 values from the population that follows $N(3.2, 0.5)$ as sample data $(x_1, x_2, x_3, x_4, x_5)$.\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|  x1  |  x2  |  x3  |  x4  |  x5  | sample mean |\n|:----:|:----:|:----:|:----:|:----:|:-----------:|\n| 2.88 | 2.94 | 3.09 | 2.66 | 2.38 |    2.79     |\n\n\n:::\n:::\n\n\n- $\\mu = 3.2$, and we use the point estimate $\\overline{x}=$ 2.79 to estimate it.\n\n\n::: question\nWhy $\\overline{x}$ is not equal to $\\mu$?\n:::\n\n. . .\n\nDue to its **randomness** nature\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-ci_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=35%}\n:::\n:::\n\n\n\n::: notes\n- Due to the **randomness** nature of drawing a sample value from the population distribution, we do not expect the statistic to be the same as the corresponding parameter.\n:::\n\n## Variability in Estimates\n\n- If another sample of size $5$ is drawn from the same population:\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|  x1  | x2  |  x3  |  x4  | x5  | sample mean |\n|:----:|:---:|:----:|:----:|:---:|:-----------:|\n| 2.35 | 3.4 | 3.97 | 1.54 | 3.5 |    2.95     |\n\n\n:::\n:::\n\n\n- The second sample mean $\\overline{x} =$ 2.95 is different from the first one.\n\n::: question\nWhy the first sample and the second sample give us different sample means?\n:::\n\n. . .\n\nA point estimator has its own *sampling distribution*\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-ci_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=35%}\n:::\n:::\n\n\n\n\n::: notes\n\n- A statistic value (point estimate) calculated from a sample varies from sample to sample because a point estimator is also a random variable, and it has its own *sampling distribution*!\n(why we learn sampling distribution. it measures the variation of a point estimator)\n\n:::\n\n\n## Why Point Estimates Are Not Enough\n\n::: question\nIf you want to estimate $\\mu$, do you prefer to report a range of values the parameter might be in, or a single estimate like $\\overline{x}$?\n:::\n\n. . .\n\n::: question\nIf you want to catch a fish, do you prefer a spear or a net?\n:::\n\n::::: columns\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/09-ci/spear.png){fig-align='center' width=70%}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/09-ci/net.png){fig-align='center' width=70%}\n:::\n:::\n\n:::\n\n:::::\n\n. . .\n\n\n- Due to variation of $\\overline{X}$, if we report a point estimate $\\overline{x}$, we probably won't hit the exact $\\mu$.\n- If we report *a range of plausible values*, we have a better shot at capturing the parameter!\n\n::: notes\n\n- the estimate $\\overline{x}$ may *not* be *precise* or *reliable*.\n\n:::\n\n\n\n## Confidence Intervals\n\nA plausible range of values for $\\mu$ is called a **confidence interval (CI)**.\n\n- To construct a CI we need to quantify the variability of our sample mean.\n<!-- - For example, if we want to construct a confidence interval for a population mean, we need to come up with a plausible range of values around our observed sample mean. -->\n<!-- - This range depends on how *precise* and *reliable* our $\\overline{X}$ is as an estimate of $\\mu$. -->\n\n- Quantifying this uncertainty requires a measurement of how much we would expect the sample statistic to vary from sample to sample. \n  + That is the *variance* of the sampling distribution of the sample mean!\n\n\n::: notes\n\n- To construct a CI we need to quantify the variability of our sample mean because the variability determines the upper and lower bound of the range of the plausible values.\n- The variability of the sample mean determines the size of CI.\n- This range depends on how *precise* and *reliable* our $\\overline{X}$ is as an estimate of $\\mu$.\n- If the variation of our sample mean is pretty large, meaning that every time we collect a sample, the sample mean varies a lot from one to another, then we are more uncertain about the value of $\\mu$.\n- And that mean the plausible range of values for $\\mu$ will be pretty wide, or the CI will be much wider.\n\n:::\n\n\n. . .\n\n::: alert\nüëâ The larger variation of $\\overline{X}$ is, the wider the CI for $\\mu$ will be, given the same \"level of confidence\".\n:::\n\n. . .\n\n::: question\nDo we know the variance of $\\overline{X}$? \n:::\n\n. . .\n\n- By CLT, $\\overline{X} \\sim N(\\mu, \\sigma^2/n)$ **regardless of what the population distribution is**.\n\n<!-- - We can quantify the variability of sample statistics using *theory via Central Limit Theorem* $\\overline{X} \\sim N(\\mu, \\sigma^2/n)$ (MATH 4720) or *simulation via Bootstrapping* (Later). -->\n\n\n::: notes\n\n<!-- .question[ -->\n<!-- If the sample mean is not so *precise* and *reliable*, do you expect the plausible range to be wider or narrower? -->\n<!-- ] -->\n\n:::\n\n\n## Confidence Interval Is for a Parameter\n\n- A confidence interval is **for a parameter, NOT a statistic.**\n  + Use the sample mean to form a confidence interval for the population mean.\n\n- We **never say** *\"The confidence interval of the sample mean $\\overline{X}$ is ...\"*\n\n- We **say** *\"The confidence interval for the true population mean $\\mu$ is ...\"*\n\n. . .\n\n- In general, a confidence interval for $\\mu$ has the form\n\n::: blackbox\n\n::: center\n\n$\\large \\overline{x} \\pm m = (\\overline{x} - m, \\overline{x} + m)$\n\n:::\n\n:::\n\n\n- The $m$ is called **margin of error**.\n\n- $\\overline{x} - m$ is the **lower bound** and $\\overline{x} + m$ is the **upper bound** of the confidence interval.\n\n- The point estimate $\\overline{x}$ and margin of error $m$ can be obtained from known quantities and our data once sampled.\n\n\n::: notes\n\n  + Use the sample variance to form a confidence interval for the population variance.\n\n:::\n\n\n\n## Precision vs. Reliability\n\n::: question\nIf we want to be very certain that we capture $\\mu$, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\n:::\n\n::: notes\n\n- Here is a question. If we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? \n- We use a wider interval because a wider interval is more likely to capture the population parameter value. So a 99% confidence interval is wider than a 95% confidence interval.\n- But What drawbacks are associated with using a wider interval?\n\n:::\n\n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/09-ci/garfield.png){fig-align='center' width=100%}\n:::\n:::\n\n\n::: notes\n\n- Let's look at this comic. \n- I can say I am 100% confident that your exam 1 score is between 0 and 100. Am I right? Yes. But do I provide helpful information? Absolutely not, the interval includes every possible score of the exam. The interval is too wide to be helpful.\n\n:::\n\n. . .\n\n::: alert\nWith the sample size fixed, precision and reliability have a trade-off relationship.\n:::\n\n\n::: notes\n\n.question[\nHow can we get best of both worlds -- high precision and high reliability/accuracy?\n]\n- How can we get best of both worlds -- high precision and high reliability/accuracy, meaning short interval with high level of confidence.\n- What we need is larger sample size, given that the sample quality is good. \n- Easy statement, but sometimes it's hard to collect more samples.\n\n:::\n\n## $(1 - \\alpha)100\\%$ Confidence Intervals\n\n- The **confidence level** $1-\\alpha$: **the proportion of times that the CI contains the population parameter, assuming that the estimation process is repeated a large number of times**.\n\n- The common choices for the confidence level are \n  + 90% $(\\alpha = 0.10)$\n  + 95% $(\\alpha = 0.05)$\n  + 99% $(\\alpha = 0.01)$\n\n- 95% is the most common level because of good balance between precision (width of the CI) and reliability (confidence level)\n\n. . .\n\n  + <span style=\"color:blue\"> **High reliability and Low precision**. I am 100% confident that the mean height of Marquette students is between 3'0\" and 8'0\". </span> duh...ü§∑\n  \n  + <span style=\"color:blue\"> **Low reliability and High precision**. I am 20% confident that mean height of Marquette students is between 5'6\" and 5'7\". </span> far from it...üôÖ\n\n\n\n\n::: notes\n\n- A confidence interval is associated with a **confidence level**.\n- The **confidence level** (often expressed as the percentage value, such as 95%)\n\n:::\n\n\n\n<!-- ## $(1 - \\alpha)100\\%$ Confidence Interval Applet -->\n\n<!-- {{< include infer-ci-ojs.qmd >}} -->\n\n\n\n## $95\\%$ Confidence Intervals for $\\mu$: Z-score\n\n:::: columns\n\n::: {.column width=\"35%\"}\n\n- $\\alpha = 0.05$\n\n- Start with the sampling distribution of $\\overline{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)$\n\n- $\\overline{x}$ will be within 1.96 SDs of the population mean $\\mu$ $95\\%$ of the time.\n\n- The $z$-score of 1.96 is associated with 2.5% area *to the right*, and called a **critical value** denoted as **$z_{0.025}$**.\n\n:::\n\n::: {.column width=\"65%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-ci_files/figure-revealjs/ci_95-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n::::\n\n::: notes\n\n (and Z = -1.96 has 2.5% area to the left);\n-At a distance of zŒ±/2 standard deviations to the right of Œº, there is an area of Œ±/2 under the normal density curve.\n\n:::\n\n\n## $95\\%$ Confidence Intervals for $\\mu$: Probability\n\n\n\n$$P\\left(\\mu-1.96\\frac{\\sigma}{\\sqrt{n}} < \\overline{X} < \\mu + 1.96\\frac{\\sigma}{\\sqrt{n}} \\right) = 0.95$$\n\n:::: columns\n\n::: {.column width=\"40%\"}\n\n\n::: question\nIs the interval $\\left(\\mu-1.96\\frac{\\sigma}{\\sqrt{n}}, \\mu+1.96\\frac{\\sigma}{\\sqrt{n}} \\right)$ our confidence interval?\n:::\n\n::: fragment\n\n‚ùå **No! We don't know $\\mu$, the quantity we like to estimate!**\n\nBut we're almost there!\n\n:::\n\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-ci_files/figure-revealjs/unnamed-chunk-13-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n:::\n\n::::\n\n\n\n\n## $95\\%$ Confidence Intervals for $\\mu$: Formula\n<!-- $$\\tiny \\begin{align} -->\n<!-- &P\\left(\\mu-1.96\\frac{\\sigma}{\\sqrt{n}} < \\overline{X} < \\mu + 1.96\\frac{\\sigma}{\\sqrt{n}} \\right) = 0.95\\\\ -->\n<!-- &P\\left( \\boxed{\\overline{X}-1.96\\frac{\\sigma}{\\sqrt{n}} < \\mu < \\overline{X} + 1.96\\frac{\\sigma}{\\sqrt{n}}} \\right) = 0.95 -->\n<!-- \\end{align}$$ -->\n$$\n\\small P\\left(\\mu-1.96\\frac{\\sigma}{\\sqrt{n}} < \\overline{X} < \\mu + 1.96\\frac{\\sigma}{\\sqrt{n}} \\right) = 0.95 \\iff\nP\\left( \\boxed{\\overline{X}-1.96\\frac{\\sigma}{\\sqrt{n}} < \\mu < \\overline{X} + 1.96\\frac{\\sigma}{\\sqrt{n}}} \\right) = 0.95$$\n\n\n:::: columns\n\n::: {.column width=\"40%\"}\n\n- <span style=\"color:blue\"> With sample data of size $n$, $\\left(\\overline{x}-1.96\\frac{\\sigma}{\\sqrt{n}},  \\overline{x} + 1.96\\frac{\\sigma}{\\sqrt{n}}\\right)$ is our $95\\%$ CI for $\\mu$ if $\\sigma$ is **known** to us! </span>\n\n- The margin of error $m = 1.96\\frac{\\sigma}{\\sqrt{n}}$.\n\n:::\n\n::: {.column width=\"60%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-ci_files/figure-revealjs/unnamed-chunk-14-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n::::\n\n# [Confidence Intervals for population Means: Known Variance Case]{.blue}{background-image=\"./images/09-ci/neyman.png\" background-size=\"cover\" background-position=\"50% 50%\" background-color=\"#447099\"}\n\n\n## Confidence Intervals for $\\mu$ When $\\sigma$ is Known\n\n**Requirements** for estimating $\\mu$ when $\\sigma$ is known:\n\n+ üëâ The sample should be a **random sample**, i.e. All data $X_i$ are drawn from the same population, and $X_i$ and $X_j$ are independent.\n  - <span style=\"color:blue\"> Any methods in the course are based on a random sample </span>\n  \n+ üëâ The population standard deviation $\\sigma$ is **known**.\n\n+ üëâ The population is either **normally distributed** or $n > 30$ or both, i.e., $X_i \\sim N(\\mu, \\sigma^2)$.\n  - <span style=\"color:blue\"> $n > 30$ allows CLT to be applied and hence normality is satisfied. </span>\n\n\n## $(1-\\alpha)100\\%$ Confidence Intervals for $\\mu$:\n\n:::: columns\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-ci_files/figure-revealjs/unnamed-chunk-15-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n::: center\n\n<span style=\"color:blue\"> $\\left(\\overline{x}-1.96\\frac{\\sigma}{\\sqrt{n}},  \\overline{x} + 1.96\\frac{\\sigma}{\\sqrt{n}}\\right)$ </span>\n<span style=\"color:blue\"> $\\left(\\overline{x}-z_{0.025}\\frac{\\sigma}{\\sqrt{n}},  \\overline{x} + z_{0.025}\\frac{\\sigma}{\\sqrt{n}}\\right)$ </span>\n\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-ci_files/figure-revealjs/ci_alpha-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n::: center\n<span style=\"color:red\"> $\\left(\\overline{x}-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}},  \\overline{x} + z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\right)$ </span>\n:::\n\n:::\n\n::::\n\n\n\n::: notes\n\n<!-- .pull-left[ -->\n<!-- - Start with the sampling distribution of $\\overline{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)$ -->\n<!-- - Sample mean $\\overline{x}$ will be within 1.96 standard deviations of the population mean $\\mu$ approximately $95\\%$ of the time. -->\n<!-- - The $z$-score of 1.96 is associated with 2.5% area to the right (and Z = -1.96 has 2.5% area to the left); -->\n<!-- ] -->\n\n:::\n\n\n## Confidence Intervals for $\\mu$ When $\\sigma$ is Known\n\n**Procedures** for constructing a confidence interval for $\\mu$ when $\\sigma$ known:\n\n  1. Check that the **requirements** are satisfied.\\\n\\\n  2. Decide $\\alpha$ or *confidence level* $(1 - \\alpha)$.\\\n\\\n  3. Find the *critical value* $z_{\\alpha/2}$.\\\n\\\n  4. Evaluate *margin of error* $m = z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}$\\\n\\\n  5. Construct the $(1 - \\alpha)100\\%$ CI for $\\mu$ using sample mean $\\overline{x}$ and margin of error $m$: \n  \n<span style=\"color:red\"> $$\\left( \\overline{x} -z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}, \\, \\overline{x} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\\right)$$</span>\n\n<!-- <span style=\"color:red\"> $$\\boxed{\\overline{x} \\pm z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\text{  or  } \\left( \\overline{x} -z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}, \\, \\overline{x} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\\right)}$$</span> -->\n\n## Example: CI for $\\mu$ When $\\sigma$ is Known\n\n:::: columns\n\n::: {.column width=\"80%\"}\n\nWe want to know the mean systolic blood pressure (SBP) of a population.\n\n  + Assume that the population distribution is normal with the standard deviation of 5 mmHg. \n  \n  + We have a random sample of 16 subjects of this population with mean 121.5.\n  \n  + Estimate the mean SBP with a 95% confidence interval.\n  \n:::\n\n\n::: {.column width=\"20%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/09-ci/blood_pressure.jpeg){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n::::\n\n. . .\n\n1. Requirements: <span style=\"color:blue\">  Normality is assumed, $\\sigma = 5$ is known and a random sample is collected.\n\n. . .\n\n2. Decide $\\alpha$: <span style=\"color:blue\">  $\\alpha = 0.05$  </span>\n\n. . .\n\n3. Find the *critical value* $z_{\\alpha/2}$: <span style=\"color:blue\">  $z_{\\alpha/2} = z_{0.025} = 1.96$  </span> \n\n. . .\n\n4. Evaluate *margin of error* $m = z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}$: <span style=\"color:blue\"> $m = (1.96) \\frac{5}{\\sqrt{16}} = 2.45$ </span> \n\n. . .\n\n5. Construct the $(1 - \\alpha)100\\%$ CI: <span style=\"color:blue\"> The 95% CI for the mean SBP is $\\overline{x} \\pm z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} = (121.5 -2.45, 121.5 + 2.45) = (119.05, 123.95)$ </span> \n\n## Computation in R\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## save all information we have\nalpha <- 0.05\nn <- 16\nx_bar <- 121.5\nsig <- 5\n\n## 95% CI\n## z-critical value\n(cri_z <- qnorm(p = alpha / 2, lower.tail = FALSE))  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.96\n```\n\n\n:::\n\n```{.r .cell-code}\n## margin of error\n(m_z <- cri_z * (sig / sqrt(n)))  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.45\n```\n\n\n:::\n\n```{.r .cell-code}\n## 95% CI for mu when sigma is known\nx_bar + c(-1, 1) * m_z  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 119.1 123.9\n```\n\n\n:::\n:::\n\n\n. . .\n\n::: question\nConstruct a 99% CI for the mean SBP. Do you expect to have a wider or narrower interval? Why?\n:::\n\n## Interpreting a Confidence Interval\n\n- <span style=\"color:blue\"> ***\"We are 95% confident that the mean SBP lies between 119.1 mm and 123.9 mm.\"*** </span>\n\n- Suppose we were able to collect our dataset many times and build the corresponding CIs. \n\n- We would expect about 95% of those intervals would contain the true population parameter, here the mean systolic blood pressure.\n  + <span style=\"color:blue\"> Remember: **$\\overline{x}$ varies from sample to sample, so does its corresponding CI**.</span>\n  \n- We never know if in fact 95% of them do, or whether any interval contains the true parameter!\n\n\n## Generate 100 Confidence Intervals Assuming $\\mu = 120$.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-ci_files/figure-revealjs/unnamed-chunk-18-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Interpreting a Confidence Interval DO NOT SAY\n\n- **WRONG** ‚ùå *\"There is a 95% chance/probability that the true population mean will fall between 119.1 mm and 123.9 mm.\"*\n- **WRONG** ‚ùå *\"The probability that the true population mean falls between 119.1 mm and 123.9 mm is 95%.\"*\n\n. . .\n\n- <span style=\"color:blue\"> üëâ **The sample mean is a random variable with a sampling distribution, so it makes sense to compute a probability of it being in some interval.** </span>\n- <span style=\"color:blue\"> üëâ **The population mean is unknown and FIXED. We cannot assign or compute any probability of it.** </span> \n\n. . .\n\n- Another inference method, **Bayesian inference**, treats $\\mu$ as a random variable and therefore we can compute any probability associated with it. (MATH 4790 Bayesian Statistics)\n\n\n\n# [Confidence Intervals for population Mean $\\mu$: Unknown Variance Case]{.orange}{background-image=\"https://upload.wikimedia.org/wikipedia/commons/4/42/William_Sealy_Gosset.jpg\" background-size=\"cover\" background-position=\"50% 50%\" background-color=\"#447099\"}\n\n\n\n## Confidence Intervals for $\\mu$ When $\\sigma$ is Unknown\n<!-- - So far we estimate unknown mean $\\mu$ with known standard deviation $\\sigma$. -->\n- $\\sigma^2 = \\frac{\\sum_{i=1}^{N}(x_i - \\mu)^2}{N}$, $N$ is the population size.\n\n- It's rare that we do not know $\\mu$, but know $\\sigma$.\n\n- We use the **Student t** distribution to construct a confidence interval for $\\mu$ when $\\sigma$ is **unknown**.\n\n- Still need\n  + Random sample\n  + Population is normally distributed and/or $n > 30$.\n  \n\n::: question\nWhat is a natural estimator for the unknown $\\sigma$?\n:::\n\n. . .\n\n- Since $\\sigma$ is unknown, we use the *sample standard deviation* $S = \\sqrt{\\frac{\\sum_{i=1}^{n}(X_i - \\overline{X})^2}{n-1}}$ instead when constructing the CI.\n\n\n::: notes\n- So far we estimate unknown mean $\\mu$ with known standard deviation $\\sigma$.\n- $\\sigma^2 = \\frac{\\sum_{i=1}^{N}(x_i - \\mu)^2}{N}$, $N$ is the population size.\n- It's rare that we do not know $\\mu$, but know $\\sigma$.\n- We use a so-called **Student t** distribution to construct a confidence intervals for $\\mu$ when $\\sigma$ is **unknown**.\n- We still need to satisfy the following:\n  + Random sample\n  + Population is normally distributed and/or $n > 30$.\n  \n.question[\nWhat is a natural estimator for the unknown $\\sigma$?\n]\n\n- Since $\\sigma$ is unknown, we use the *sample standard deviation* $S = \\sqrt{\\frac{\\sum_{i=1}^{n}(X_i - \\overline{X})^2}{n-1}}$ instead when constructing the CI.\n:::\n\n\n## Student t Distribution\n\n- If the population is normally distributed or $n > 30$,\n  + $\\overline{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n} \\right)$\n  + $Z = \\frac{\\overline{X} - \\mu}{\\color{red}\\sigma/\\sqrt{n} } \\sim N(0, 1)$\n  + <span style=\"color:blue\">  $T = \\frac{\\overline{X} - \\mu}{\\color{red}S/\\sqrt{n} } \\sim t_{n-1}$ </span> \n  + $t_{n-1}$ denotes the Student t distribution with **degrees of freedom (df)** $n-1$.\n\n\n\n\n## Properties of Student t Distribution\n\n- Symmetric about the mean 0 and bell-shaped as $N(0, 1)$.\n\n- More variability than $N(0, 1)$ (heavier tails and lower peak).\n\n- The variability is different for different sample sizes (degrees of freedom).\n\n- As $n \\rightarrow \\infty$ $(df \\rightarrow \\infty)$, the Student t distribution approaches to $N(0, 1)$.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-ci_files/figure-revealjs/unnamed-chunk-19-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n\n\n<!-- ## Student t Distribution Applet -->\n\n<!-- {{< include infer-ci-t-ojs.qmd >}} -->\n\n\n\n## Critical Values of $t_{\\alpha/2, n-1}$\n\n- When $\\sigma$ is unknown, we use $t_{\\alpha/2, n-1}$ as the critical value, instead of $z_{\\alpha/2}$.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-ci_files/figure-revealjs/unnamed-chunk-20-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n. . .\n\n::: question\nWith the same $\\alpha$, $t_{\\alpha, n-1}$ or $z_{\\alpha}$ is larger?\n:::\n\n\n## Critical Values of $t_{\\alpha/2, n-1}$\n\n::: alert\nGiven the same confidence level $1-\\alpha$, $t_{\\alpha/2, n-1} > z_{\\alpha/2}$.\n:::\n\n<br>\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n| Level | t df = 5 | t df = 15 | t df = 30 | t df = 1000 | t df = inf |  z   |\n|:-----:|:--------:|:---------:|:---------:|:-----------:|:----------:|:----:|\n|  90%  |   2.02   |   1.75    |   1.70    |    1.65     |    1.64    | 1.64 |\n|  95%  |   2.57   |   2.13    |   2.04    |    1.96     |    1.96    | 1.96 |\n|  99%  |   4.03   |   2.95    |   2.75    |    2.58     |    2.58    | 2.58 |\n\n\n:::\n:::\n\n\n## CI for $\\mu$ When $\\sigma$ is Unknown\n\n- The $(1-\\alpha)100\\%$ confidence interval for $\\mu$ when $\\sigma$ is **unknown** is <span style=\"color:blue\"> $$\\left(\\overline{x} - t_{\\alpha/2, n-1} \\frac{s}{\\sqrt{n}}, \\overline{x} + t_{\\alpha/2, n-1} \\frac{s}{\\sqrt{n}}\\right)$$ </span>\n\n- Given the same confidence level $1-\\alpha$, $t_{\\alpha/2, n-1} > z_{\\alpha/2}$.\n\n::: alert\nWe are more \"uncertain\" when doing inference about $\\mu$ because we also don't have information about $\\sigma$, and replacing it with $s$ adds additional uncertainty.\n:::\n\n\n## Computation in R (t interval)\n\n- Back to the systolic blood pressure (SBP) example. We have $n=16$ and $\\overline{x} = 121.5$.\n\n- Estimate the mean SBP with a 95% confidence interval with **unknown $\\sigma$ and $s = 5$.**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nalpha <- 0.05\nn <- 16\nx_bar <- 121.5\ns <- 5  ## sigma is unknown and s = 5\n\n## t-critical value\n(cri_t <- qt(p = alpha / 2, df = n - 1, lower.tail = FALSE)) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.131\n```\n\n\n:::\n\n```{.r .cell-code}\n## margin of error\n(m_t <- cri_t * (s / sqrt(n)))  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.664\n```\n\n\n:::\n\n```{.r .cell-code}\n## 95% CI for mu when sigma is unknown\nx_bar + c(-1, 1) * m_t  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 118.8 124.2\n```\n\n\n:::\n:::\n\n\n## Summary\n\n|      | Numerical Data, $\\sigma$ known | Numerical Data, $\\sigma$ unknown   |\n|:-------------:|:-----------------:|:----------------:|\n| **Parameter of Interest** | Population Mean $\\mu$  | Population Mean $\\mu$ |  \n| **Confidence Interval**   | $\\bar{x} \\pm z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}$ | $\\bar{x} \\pm t_{\\alpha/2, n-1} \\frac{s}{\\sqrt{n}}$           |\n\n. . .\n\n- Remember to check if the population is normally distributed or $n>30$.\n\n. . .\n\n- What if the population is not normal and $n \\le 30$?\n\n. . .\n\n- Use a so-called **nonparametric** method, for example **bootstrapping**. (Your project?!)\n\n<!-- (MATH 4750 Statistical Computing) -->\n\n<!-- --- -->\n<!-- ## $(1 - \\alpha)\\%$ Confidence Intervals for $\\mu$ -->\n<!-- $$ -->\n<!-- \\begin{align} -->\n<!-- &P\\left(-z_{\\alpha/2} < Z < z_{\\alpha/2} \\right) = 1 - \\alpha\\\\ -->\n<!-- \\iff &P\\left(-z_{\\alpha/2} < \\frac{\\overline{X} - \\mu}{\\frac{\\sigma}{\\sqrt{n}} } < z_{\\alpha/2} \\right) = 1 - \\alpha\\\\ -->\n<!-- \\iff &P\\left(-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} < \\overline{X} - \\mu < z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\right) = 1 - \\alpha\\\\ -->\n<!-- \\iff &P\\left(\\mu-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} < \\overline{X} < \\mu + z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\right) = 1 - \\alpha\\\\ -->\n<!-- \\iff &P\\left( \\boxed{\\overline{X}-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} < \\mu < \\overline{X} + z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}} \\right) = 1 - \\alpha -->\n<!-- \\end{align} -->\n<!-- $$ -->\n\n<!-- --- -->\n<!-- - With CLT, $\\overline{X}$ is approximately $N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)$. -->\n<!-- - With $z_{\\alpha/2}$ being $(1-\\alpha/2)$ quantile of $N(0, 1)$, $(1 - \\alpha)100\\%$ confidence interval for $\\mu$ is $\\left(\\overline{X} - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}, \\overline{X} + z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\right)$ -->\n\n",
    "supporting": [
      "09-ci_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}