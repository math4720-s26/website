{
  "hash": "46846e22e1f2e38e40a4728df4852a95",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Inference About Population Variances `<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 640 512\" style=\"height:1em;width:1.25em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M64 64a64 64 0 1 1 128 0A64 64 0 1 1 64 64zM25.9 233.4C29.3 191.9 64 160 105.6 160h44.8c27 0 51 13.4 65.5 34.1c-2.7 1.9-5.2 4-7.5 6.3l-64 64c-21.9 21.9-21.9 57.3 0 79.2L192 391.2V464c0 26.5-21.5 48-48 48H112c-26.5 0-48-21.5-48-48V348.3c-26.5-9.5-44.7-35.8-42.2-65.6l4.1-49.3zM448 64a64 64 0 1 1 128 0A64 64 0 1 1 448 64zM431.6 200.4c-2.3-2.3-4.9-4.4-7.5-6.3c14.5-20.7 38.6-34.1 65.5-34.1h44.8c41.6 0 76.3 31.9 79.7 73.4l4.1 49.3c2.5 29.8-15.7 56.1-42.2 65.6V464c0 26.5-21.5 48-48 48H496c-26.5 0-48-21.5-48-48V391.2l47.6-47.6c21.9-21.9 21.9-57.3 0-79.2l-64-64zM272 240v32h96V240c0-9.7 5.8-18.5 14.8-22.2s19.3-1.7 26.2 5.2l64 64c9.4 9.4 9.4 24.6 0 33.9l-64 64c-6.9 6.9-17.2 8.9-26.2 5.2s-14.8-12.5-14.8-22.2V336H272v32c0 9.7-5.8 18.5-14.8 22.2s-19.3 1.7-26.2-5.2l-64-64c-9.4-9.4-9.4-24.6 0-33.9l64-64c6.9-6.9 17.2-8.9 26.2-5.2s14.8 12.5 14.8 22.2z\"/></svg>`{=html}'\ntitle-slide-attributes:\n  data-background-image: ../images/bg.png\n  # data-background-size: stretch\n  # data-slide-number: none\nformat: \n  live-revealjs: \n    output-file: 12-infer-variance-slides.html\n    # theme: slides.scss\nwebr:\n  cell-options:\n    autorun: false\n  packages:\n    - tidyverse\nknitr:\n  opts_chunk:\n    out-width: 100%\n    echo: false\n---\n\n\n# {visibility=\"hidden\"}\n\n\\def\\bx{\\mathbf{x}}\n\\def\\bg{\\mathbf{g}}\n\\def\\bw{\\mathbf{w}}\n\\def\\bbeta{\\boldsymbol \\beta}\n\\def\\bX{\\mathbf{X}}\n\\def\\by{\\mathbf{y}}\n\\def\\bH{\\mathbf{H}}\n\\def\\bI{\\mathbf{I}}\n\\def\\bS{\\mathbf{S}}\n\\def\\bW{\\mathbf{W}}\n\\def\\T{\\text{T}}\n\\def\\cov{\\mathrm{Cov}}\n\\def\\cor{\\mathrm{Corr}}\n\\def\\var{\\mathrm{Var}}\n\\def\\E{\\mathrm{E}}\n\\def\\bmu{\\boldsymbol \\mu}\n\\DeclareMathOperator*{\\argmin}{arg\\,min}\n\\def\\Trace{\\text{Trace}}\n\n\n\n\n<!-- begin: webr fodder -->\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n<!-- end: webr fodder -->\n\n\n<!-- # [Hypothesis Testing]{.orange}{background-image=\"https://upload.wikimedia.org/wikipedia/commons/4/42/William_Sealy_Gosset.jpg\" background-size=\"cover\" background-position=\"50% 50%\" background-color=\"#447099\"} -->\n\n# Inference About Population Variances\n\n- ### One Population Variance\n- ### Comparing Two Population Variances\n\n\n\n\n# [Inference for One Population Variance]{.orange}{background-image=\"./images/12-infer-variance/pearson_quote.jpg\" background-size=\"cover\" background-position=\"50% 50%\" background-color=\"#447099\"}\n\n\n## Why Inference for Population Variances?\n\n- We like to know if $\\sigma_1 = \\sigma_2$, so a correct or better method can be used. \n\n::: question\nWhich test we learned needs $\\sigma_1 = \\sigma_2$?\n:::\n\n. . .\n\n::: center\nIn some situations, we care about *variation*!\n:::\n\n\n:::: columns\n\n::: {.column width=\"50%\"}\n\n- <span style=\"color:blue\"> the variation in potency of drugs</span>: *affects patients' health*\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/12-infer-variance/drug.jpeg){fig-align='center' width=78%}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n- <span style=\"color:blue\"> the variance of stock prices </span>: *the higher the variance, the riskier the investment*\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/12-infer-variance/stock.jpeg){fig-align='center' width=78%}\n:::\n:::\n\n\n:::\n\n::::\n\n\n::: notes\n\n- When doing inference for population means, \n- We like to know if $\\sigma_1 = \\sigma_2$, so that a correct or better method can be used. For example, we use the pooled $t$-test if $\\sigma_1 = \\sigma_2$ or they are very close to each other for higher power.\n- drug for lowering BP. We hope the same amount or dose level of the drug provide the same effect on each individual. We don't want some patients BP is lowered a lot, but some other patient's BP is lowered just a little bit. \n- We want the new treatment can provide consistent potency and efficacy for all patients.\n\n:::\n\n\n\n## Inference for Population Variances\n\n- The sample variance $S^2 = \\frac{\\sum_{i=1}^n(X_i - \\overline{X})^2}{n-1}$ is our **point estimator** for the population variance $\\sigma^2$.\n  <!-- + $S^2$ is an **unbiased estimator** for $\\sigma^2$, i.e., $E(S^2) = \\sigma^2$ -->\n\n- The inference for $\\sigma^2$ needs the population to be **normal**. \n\n::: alert\n❗ The methods can **work poorly if the normality is violated, even the sample is large**.\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/12-infer-variance/normal_dist.jpeg){fig-align='center' width=40%}\n:::\n:::\n\n\n\n::: notes\n\n- In some situations, we do care about variation. \n  + <span style=\"color:blue\"> the variation in potency of drugs</span>: affects patients' health\n  + <span style=\"color:blue\"> the variance of stock prices </span>: the higher the variance, the riskier the investment\n\n- Intuitively, the sample variance $S^2 = \\frac{\\sum_{i=1}^n(X_i - \\overline{X})^2}{n-1}$ is our **point estimator** for the population variance $\\sigma^2$.\n\n- For a random sample of size $n$ drawn from a population with mean $\\mu$ and variance $\\sigma^2$, $S^2$ is an **unbiased estimator** for $\\sigma^2$.\n\n- In Chapter 7, we discuss inference methods for $\\sigma^2$ when the population is assumed **normal**. **The methods discussed here can work poorly if normality is violated, even if the sample is large**.\n\n:::\n\n## Chi-Squared $\\chi^2$ Distribution\n\nThe inference for $\\sigma^2$ involves the $\\chi^2$ distribution.\n\n:::: columns\n\n::: {.column width=\"30%\"}\n\n- Defined over *positive* numbers\n\n- Parameter: degrees of freedom $df$\n\n- *Right* skewed\n\n- More symmetric as $df$ gets larger\n<!-- - [Chi-Squared Distribution](https://homepage.divms.uiowa.edu/~mbognar/applets/chisq.html) -->\n:::\n\n\n::: {.column width=\"70%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](12-infer-variance_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n::::\n\n\n<!-- ## Chi-Squared $\\chi^2$ Distribution Applet -->\n\n<!-- {{< include infer-var-chisq-ojs.qmd >}} -->\n\n\n\n## Upper Tail and Lower Tail of Chi-Square\n\n<!-- - $\\chi^2_{c,\\, df}$ is the $\\chi^2$ value of $\\chi^2_{df}$ distribution that has area to the **right** of $c$. -->\n\n- $\\chi^2_{\\frac{\\alpha}{2},\\, df}$ has area to the **right** of $\\alpha/2$.\n\n- $\\chi^2_{1-\\frac{\\alpha}{2},\\, df}$ has area to the **left** of $\\alpha/2$.\n\n- In $N(0, 1)$, $z_{1-\\frac{\\alpha}{2}} = -z_{\\frac{\\alpha}{2}}$. But $\\chi^2_{1-\\frac{\\alpha}{2},\\,df} \\ne -\\chi^2_{\\frac{\\alpha}{2},\\,df}$ because of **non**-symmetry of the $\\chi^2$ distribution.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](12-infer-variance_files/figure-revealjs/chi2-critical-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n::: notes\n\n- Define critical values $\\chi_U^2$ and $\\chi_L^2$.\n- When constructing a CI with level $1-\\alpha$, we put $1-\\alpha$ in the middle and\n\n:::\n\n\n\n## Sampling Distribution \n\n- When a random sample of size $n$ is from $\\color{red}{N(\\mu, \\sigma^2)}$, \n$$ \\frac{(n-1)S^2}{\\sigma^2} \\sim \\chi^2_{n-1} $$\n<!-- - The sampling distribution is approximately normal for large sample sizes. -->\n\n- The inference method for $\\sigma^2$ introduced here can work poorly if the normality assumption is violated, even for large samples!\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](12-infer-variance_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## $(1-\\alpha)100\\%$ Confidence Interval for $\\sigma^2$\n\n:::: columns\n\n::: {.column width=\"40%\"}\n\n$(1-\\alpha)100\\%$ CI for $\\sigma^2$ is \n$$\\color{blue}{\\left( \\frac{(n-1)S^2}{\\chi^2_{\\frac{\\alpha}{2}, \\, n-1}}, \\frac{(n-1)S^2}{\\chi^2_{1-\\frac{\\alpha}{2}, \\, n-1}} \\right)}$$ \n\n:::\n\n::: {.column width=\"60%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](12-infer-variance_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n::::\n\n::: alert\n\n❗ The CI for $\\sigma^2$ **cannot** be expressed as $(S^2-m, S^2+m)$ anymore!\n\n:::\n\n\n<!-- - $\\chi_U^2$ is the upper-tail value of chi-square for $df = n-1$ with area $\\alpha/2$ to its right. -->\n\n<!-- - $\\chi_L^2$ is the lower-tail value of chi-square for $df = n-1$ with area $\\alpha/2$ to its left. -->\n\n\n\n## Example: Supermodel Heights\n\n:::: columns\n\n::: {.column width=\"85%\"}\n\nListed below are heights (cm) for the simple random sample of 16 female supermodels:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nheights <- c(178, 177, 176, 174, 175, 178, 175, 178, \n             178, 177, 180, 176, 180, 178, 180, 176)\n```\n:::\n\n- The supermodels' height is normally distributed.\n- Construct a $95\\%$ confidence interval for population standard deviation $\\sigma$.\n\n:::\n\n::: {.column width=\"15%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/12-infer-variance/models.jpeg){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n::::\n\n. . .\n\n- $n = 16$, $s^2 = 3.4$, $\\alpha = 0.05$.\n\n- $\\chi^2_{\\alpha/2, n-1} = \\chi^2_{0.025, 15} = 27.49$\n\n- $\\chi^2_{1-\\alpha/2, n-1} = \\chi^2_{0.975, 15} = 6.26$\n\n. . .\n\n- The $95\\%$ CI for $\\sigma$ is $\\small \\left( \\sqrt{\\frac{(n-1)s^2}{\\chi^2_{\\frac{\\alpha}{2}, \\, n-1}}}, \\sqrt{\\frac{(n-1)s^2}{\\chi^2_{1-\\frac{\\alpha}{2}, \\, n-1}}} \\right) = \\left( \\sqrt{\\frac{(16-1)(3.4)}{27.49}}, \\sqrt{\\frac{(16-1)(3.4)}{6.26}}\\right) = (1.36, 2.85)$\n\n\n## Example: Computation in R\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nn <- 16\ns2 <- var(heights)\nal <- 0.05\n\n## two chi-square critical values\nchi2_right <- qchisq(al / 2, df = n - 1, lower.tail = FALSE)\nchi2_left <- qchisq(al / 2, df = n - 1, lower.tail = TRUE)\n\n## two bounds of CI for sigma2\nci_lwr <- (n - 1) * s2 / chi2_right\nci_upr <- (n - 1) * s2 / chi2_left\n```\n:::\n\n\n<br>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## two bounds of CI for sigma\nsqrt(ci_lwr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.36\n```\n\n\n:::\n\n```{.r .cell-code}\nsqrt(ci_upr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.85\n```\n\n\n:::\n:::\n\n\n## Example Cont'd: Testing\n\nUse $\\alpha = 0.05$ to test the claim that \"*supermodels have heights with a standard deviation that is less than $\\sigma = 7.5$ cm for the population of women*\". \n\n. . .\n\n\n- **Step 1**: $H_0: \\sigma = \\sigma_0$ vs. $H_1: \\sigma < \\sigma_0$. Here $\\sigma_0 = 7.5$ cm\n\n. . .\n\n- **Step 2**: $\\alpha = 0.05$\n\n. . .\n\n- **Step 3**: Under $H_0$, $\\chi_{test}^2 = \\frac{(n-1)s^2}{\\sigma_0^2} = \\frac{(16-1)(3.4)}{7.5^2} = 0.91$, a statistic drawn from $\\chi^2_{n-1}$.\n\n. . .\n\n:::: columns\n\n::: {.column width=\"50%\"}\n\n- **Step 4-c**: This is a left-tailed test. The critical value is $\\chi_{1-\\alpha, df}^2 = \\chi_{0.95, 15}^2 = 7.26$\n- **Step-5-c**: Reject $H_0$ in favor of $H_1$ if $\\chi_{test}^2 < \\chi_{1-\\alpha, df}^2$. Since $0.91 < 7.26$, we reject $H_0$.\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](12-infer-variance_files/figure-revealjs/unnamed-chunk-12-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n:::\n\n::::\n\n\n\n## Example Cont'd: Testing\n\n\nUse $\\alpha = 0.05$ to test the claim that \"*supermodels have heights with a standard deviation that is less than $\\sigma = 7.5$ cm for the population of women*\". \n\n- **Step 1**: $H_0: \\sigma = \\sigma_0$ vs. $H_1: \\sigma < \\sigma_0$. Here $\\sigma_0 = 7.5$ cm\n\n- **Step 2**: $\\alpha = 0.05$\n\n- **Step 3**: Under $H_0$, $\\chi_{test}^2 = \\frac{(n-1)s^2}{\\sigma_0^2} = \\frac{(16-1)(3.4)}{7.5^2} = 0.91$, a statistic drawn from $\\chi^2_{n-1}$.\n\n\n:::: columns\n\n::: {.column width=\"50%\"}\n\n- **Step 6**: There is sufficient evidence to support the claim that supermodels have heights with a SD that is less than the SD for the population of women.\n\n*Heights of supermodels vary less than heights of women in the general population.*\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](12-infer-variance_files/figure-revealjs/unnamed-chunk-13-1.png){fig-align='center' width=85%}\n:::\n:::\n\n\n:::\n\n::::\n\n\n\n\n## Back to Pooled t-Test\n\nIn a pooled t-test, we assume\n\n  + <span style=\"color:blue\"> both samples are of large size or drawn from a normal population. </span>\n\n  + <span style=\"color:blue\"> $\\sigma_1 = \\sigma_2$ </span>\n\n. . .\n\n- Use QQ-plot (and normality tests, Anderson, Shapiro, etc) to check the assumption of normal distribution. \n\n- We learn to check the assumption $\\sigma_1 = \\sigma_2$.\n\n::: notes\n- Whenever we use t-statistics, there are assumptions. \n:::\n\n\n\n# [Inference for Comparing Two Population Variances]{.orange}{background-image=\"./images/12-infer-variance/pearson_quote.jpg\" background-size=\"cover\" background-position=\"50% 50%\" background-color=\"#447099\"}\n\n## F Distribution\n\n<!-- - We use **$\\chi^2$ distribution** for the inference about **one** population variance. -->\n\nWe use **$F$ distribution** for the inference about **two** population variances.\n\n:::: columns\n\n::: {.column width=\"30%\"}\n\n- Two parameters: $df_1$, $df_2$\n\n- *Right* skewed\n\n- Defined over *positive* numbers\n\n<!-- - [F Distribution](https://homepage.divms.uiowa.edu/~mbognar/applets/f.html) -->\n<!-- ] -->\n\n:::\n\n::: {.column width=\"70%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](12-infer-variance_files/figure-revealjs/unnamed-chunk-14-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n::::\n\n\n\n<!-- ## F Distribution Applet -->\n\n\n<!-- {{< include infer-var-f-ojs.qmd >}} -->\n\n\n\n\n## Upper and Lower Tail of F Distribution\n\n- We denote $F_{\\alpha, \\, df_1, \\, df_2}$ as the $F$ quantile so that $P(F_{df_1, df_2} > F_{\\alpha, \\, df_1, \\, df_2}) = \\alpha$.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](12-infer-variance_files/figure-revealjs/f-critical-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Sampling Distribution\n\n<!-- - If $U_1 \\sim \\chi^2_{n_1-1}$ and $U_2 \\sim \\chi^2_{n_2-1}$ and $U_1$ and $U_2$ are independent, the random variable $$X =  \\frac{\\frac{U_1}{n_1-1}}{\\frac{U_2}{n_2-1}}$$ follows $F_{n_1-1, \\, n_2-1}$ distribution. -->\n \n- The random samples of size $n_1$ and $n_2$ are *independent* from two normal populations, $N(\\mu_1, \\sigma_1^2)$ and $N(\\mu_2, \\sigma_2^2)$.\n\n- The ratio $$\\frac{S_1^2/S_2^2}{\\sigma_1^2/\\sigma_2^2} \\sim F_{n_1-1, \\, n_2-1}$$\n\n\n\n\n::: notes\n\n<!-- .question[ -->\n<!-- Can you show why? -->\n<!-- ] -->\n$$\\frac{s_1^2/\\sigma_1^2}{s_2^2/\\sigma_2^2} = \\frac{s_1^2/s_2^2}{\\sigma_1^2/\\sigma_2^2} \\sim F_{n_1-1, \\, n_2-1}$$\n\n:::\n\n\n\n## $(1-\\alpha)100\\%$ Confidence Interval for $\\sigma_1^2 / \\sigma_2^2$\n\n:::: columns\n\n::: {.column width=\"40%\"}\n\n$(1-\\alpha)100\\%$ CI for $\\sigma_1^2 / \\sigma_2^2$ is \n$$\\color{blue}{\\left( \\frac{s_1^2/s_2^2}{F_{\\alpha/2, \\, n_1 - 1, \\, n_2 - 1}}, \\frac{s_1^2/s_2^2}{F_{1-\\alpha/2, \\, \\, n_1 - 1, \\, n_2 - 1}} \\right)}$$\n\n:::\n\n::: {.column width=\"60%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](12-infer-variance_files/figure-revealjs/unnamed-chunk-15-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n::::\n\n\n::: alert\n\n❗ The CI for $\\sigma_1^2 / \\sigma_2^2$ **cannot** be expressed as $\\left(\\frac{s_1^2}{s_2^2}-m, \\frac{s_1^2}{s_2^2} + m\\right)$ anymore!\n\n:::\n\n\n## F test for comparing $\\sigma_1^2$ and $\\sigma_2^2$\n\n::: {.midi}\n\n- **Step 1**: right-tailed <span style=\"color:blue\"> $\\small \\begin{align} &H_0: \\sigma_1 \\le \\sigma_2 \\\\ &H_1: \\sigma_1 > \\sigma_2 \\end{align}$ </span>\n  and two-tailed <span style=\"color:green\"> $\\small \\begin{align} &H_0: \\sigma_1 = \\sigma_2 \\\\ &H_1: \\sigma_1 \\ne \\sigma_2 \\end{align}$ </span>\n\n::: fragment\n\n- **Step 2**: $\\alpha = 0.05$\n\n:::\n\n::: fragment\n\n- **Step 3**: Under $H_0$, $\\sigma_1 = \\sigma_2$, and the test statistic is\n\n$$\\small F_{test} = \\frac{s_1^2/s_2^2}{\\sigma_1^2/\\sigma_2^2} = \\frac{s_1^2}{s_2^2} \\sim F_{n_1-1, \\, n_2-1}$$\n\n:::\n\n::: fragment\n- **Step 4-c**: \n  + Right-tailed: <span style=\"color:blue\"> $F_{\\alpha, \\, n_1-1, \\, n_2-1}$ </span>. \n  + Two-tailed: <span style=\"color:green\"> $F_{\\alpha/2, \\, n_1-1, \\, n_2-1}$ or $F_{1-\\alpha/2, \\, n_1-1, \\, n_2-1}$ </span>\n\n:::\n\n::: fragment\n\n- **Step 5-c**: \n  + Right-tailed: reject $H_0$ if <span style=\"color:blue\"> $F_{test} \\ge F_{\\alpha, \\, n_1-1, \\, n_2-1}$</span>. \n  + Two-tailed: reject $H_0$ if <span style=\"color:green\"> $F_{test} \\ge F_{\\alpha/2, \\, n_1-1, \\, n_2-1}$ or $F_{test} \\le F_{1-\\alpha/2, \\, n_1-1, \\, n_2-1}$</span>\n\n:::\n\n:::\n\n\n## Back to the Weight Loss Example\n\n:::: columns\n\n::: {.column width=\"80%\"}\nA study was conducted to see the effectiveness of a weight loss program.\n\n- Two groups (Control and Experimental) of 10 subjects were selected.\n\n- The two populations are normally distributed and have the same SD.\n:::\n\n::: {.column width=\"20%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/12-infer-variance/weight.jpeg){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n::::\n\n\n- The data on weight loss was collected at the end of six months\n  + **Control**: $n_1 = 10$, $\\overline{x}_1 = 2.1\\, lb$, $s_1 = 0.5\\, lb$\n  + **Experimental**: $n_2 = 10$, $\\overline{x}_2 = 4.2\\, lb$, $s_2 = 0.7\\, lb$\n\n- Assumptions:\n\n  + <span style=\"color:blue\"> $\\sigma_1 = \\sigma_2$ </span>\n  \n  + The weight loss for both groups are normally distributed.\n  \n  \n## Back to the Weight Loss Example: Check if $\\sigma_1 = \\sigma_2$\n\n:::: columns\n\n::: {.column width=\"45%\"}\n\n- $n_1 = 10$, $s_1 = 0.5 \\, lb$\n\n- $n_2 = 10$, $s_2 = 0.7 \\, lb$\n\n- **Step 1**: \n  $\\begin{align} &H_0: \\sigma_1 = \\sigma_2 \\\\ &H_1: \\sigma_1 \\ne \\sigma_2 \\end{align}$\n\n- **Step 2**: $\\alpha = 0.05$\n\n- **Step 3**: $F_{test} = \\frac{s_1^2}{s_2^2} = \\frac{0.5^2}{0.7^2} = 0.51$.\n\n- **Step 4-c**: Two-tailed test. The critical value is $F_{0.05/2, \\, 10-1, \\, 10-1} = 4.03$ or $F_{1-0.05/2, \\, 10-1, \\, 10-1} = 0.25$.\n:::\n\n::: {.column width=\"55%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](12-infer-variance_files/figure-revealjs/unnamed-chunk-17-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n::::\n\n\n\n- **Step 5-c**: Is $F_{test} > 4.03$ or $F_{test} < 0.25$? No.\n\n- **Step 6**: The evidence is not sufficient to reject the claim that $\\sigma_1 = \\sigma_2$.\n\n\n\n## Back to the Weight Loss Example: 95% CI for $\\sigma_1^2 / \\sigma_2^2$\n\n:::: columns\n\n::: {.column width=\"35%\"}\n\n<!-- - $\\small F_{\\alpha/2, \\, df_1, \\, df_2} = F_{0.05/2, \\, 10-1, \\, 10-1} = 4.03$  -->\n\n<!-- - $\\small F_{1-\\alpha/2, \\, df_1, \\, df_2} = F_{1-0.05/2, \\, 10-1, \\, 10-1} = 0.25$ -->\n\n<!-- - $\\small \\frac{s_1^2}{s_2^2} = \\frac{0.5^2}{0.7^2} = 0.51$ -->\n\n- The 95% CI for $\\sigma_1^2 / \\sigma_2^2$ is \n$$\\small \\begin{align} &\\left( \\frac{s_1^2/s_2^2}{F_{\\alpha/2, \\, df_1, \\, df_2}}, \\frac{s_1^2/s_2^2}{F_{1-\\alpha/2, \\, df_1, \\, df_2}} \\right) \\\\ &= \\left( \\frac{0.51}{4.03}, \\frac{0.51}{0.25} \\right) = \\left(0.13, 2.04\\right)\\end{align}$$\n- We are 95% confident that the ratio $\\sigma_1^2 / \\sigma_2^2$ is between 0.13 and 2.04.\n\n:::\n\n\n::: {.column width=\"65%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](12-infer-variance_files/figure-revealjs/unnamed-chunk-18-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n\n::::\n\n\n\n\n\n\n## Implementing F-test in R\n\n<!-- - **`qf(p = alpha, df1 = n1 - 1, df2 = n2 - 1, lower.tail = FALSE)`** to find $F_{\\alpha, \\, n_1-1, \\, n_2-1}$. -->\n\n:::: columns\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nn1 <- 10; n2 <- 10\ns1 <- 0.5; s2 <- 0.7\nal <- 0.05\n\n## 95% CI for sigma_1^2 / sigma_2^2\nf_small <- qf(p = al / 2, \n              df1 = n1 - 1, df2 = n2 - 1, \n              lower.tail = TRUE)\nf_big <- qf(p = al / 2, \n            df1 = n1 - 1, df2 = n2 - 1, \n            lower.tail = FALSE)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## lower bound\n(s1 ^ 2 / s2 ^ 2) / f_big\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.127\n```\n\n\n:::\n\n```{.r .cell-code}\n## upper bound\n(s1 ^ 2 / s2 ^ 2) / f_small\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.05\n```\n\n\n:::\n:::\n\n\n:::\n\n\n::: {.column width=\"50%\"}\n\n::: fragment\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## Testing sigma_1 = sigma_2\n(test_stats <- s1 ^ 2 / s2 ^ 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.51\n```\n\n\n:::\n\n```{.r .cell-code}\n(cri_big <- qf(p = al / 2, \n               df1 = n1 - 1, \n               df2 = n2 - 1, \n               lower.tail = FALSE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4.03\n```\n\n\n:::\n\n```{.r .cell-code}\n(cri_small <- qf(p = al / 2, \n                 df1 = n1 - 1, \n                 df2 = n2 - 1, \n                 lower.tail = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.248\n```\n\n\n:::\n\n```{.r .cell-code}\n# var.test(x, y, alternative = \"two.sided\")\n```\n:::\n\n\n:::\n\n::::\n\n\n",
    "supporting": [
      "12-infer-variance_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}